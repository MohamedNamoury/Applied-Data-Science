dtree_fit_gini <- train(Churn~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
print(dtree_fit_gini)
pred_tree <- predict(dtree_fit_gini, test_set)
print("Confusion Matrix for Decision Tree"); table(Predicted = pred_tree, Actual = test_set$Churn)
dataset = read.csv("customer_churn.csv")
dataset[dataset == "Yes"] <- 1
dataset[dataset == "No"] <- 0
dataset$Churn <- as.numeric(as.character(dataset$Churn))
head(dataset)
dataset = subset(dataset, select =  - customerID  )
na.omit(dataset)
head(dataset)
train.index <- sample(c(1:dim(dataset)[1]), dim(dataset)[1]*0.67)
train.df <- dataset[train.index, ]
valid.df <-dataset[-train.index, ]
label <- length(dataset$Churn)
train_length <- length(train.df$Churn)
test_length <- length(valid.df$Churn)
H <- c(label, train_length, test_length)
M <- c("Dataset","Train","Test")
barplot(H, names.arg = M)
dim(train.df)
sapply(train.df, class)
table(train.df$Churn)
install.packages("ROSE")
library(ROSE)
train_set <- ovun.sample(Churn~., data=train.df,
N=nrow(train.df), p=0.2,
seed=1, method="both")$data
table(data.balanced.ou$Churn)
library("party")
install.packages("ROSE")
install.packages("ROSE")
prop.table(table(train_set$Churn))
####################
#Feature Importance
###################
set.seed(300)
model <- rpart(Churn~., data =  train_set, method = "class")
importance <- varImp(model, scale = FALSE)
print(importance)
train_set = subset(train_set, select = -c(gender,Partner,Dependents,StreamingMovies))
test_set = subset(valid.df, select = -c(gender,Partner,Dependents,StreamingMovies))
library(rpart)
library(rpart.plot)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
library(rpart)
library(rpart.plot)
library(readr)
library(caTools)
library(dplyr)
require(tree)
library(caTools)
library(mlbench)
library(caret)
library(adabag)
library(rpart)
library("rpart.plot")
library(randomForest)
library(pROC)
library(ROSE)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
print(dtree_fit_gini)
pred_tree <- predict(dtree_fit_gini, test_set)
print("Confusion Matrix for Decision Tree"); table(Predicted = pred_tree, Actual = test_set$Churn)
print("Confusion Matrix for Decision Tree"); table(Predicted = as.factor(pred_tree), Actual = as.factor(test_set$Churn))
dataset = read.csv("customer_churn.csv")
dataset[dataset == "Yes"] <- 1
dataset[dataset == "No"] <- 0
dataset$Churn <- as.numeric(as.character(dataset$Churn))
head(dataset)
dataset = subset(dataset, select =  - customerID  )
dataset  = na.omit(dataset)
head(dataset)
train.index <- sample(c(1:dim(dataset)[1]), dim(dataset)[1]*0.67)
train.df <- dataset[train.index, ]
valid.df <-dataset[-train.index, ]
label <- length(dataset$Churn)
train_length <- length(train.df$Churn)
test_length <- length(valid.df$Churn)
H <- c(label, train_length, test_length)
M <- c("Dataset","Train","Test")
barplot(H, names.arg = M)
dim(train.df)
sapply(train.df, class)
table(train.df$Churn)
install.packages("ROSE")
install.packages("ROSE")
train_set <- ovun.sample(Churn~., data=train.df,
N=nrow(train.df), p=0.2,
seed=1, method="both")$data
table(data.balanced.ou$Churn)
library("party")
prop.table(table(train_set$Churn))
####################
#Feature Importance
###################
set.seed(300)
model <- rpart(Churn~., data =  train_set, method = "class")
importance <- varImp(model, scale = FALSE)
print(importance)
train_set = subset(train_set, select = -c(gender,Partner,Dependents,StreamingMovies))
test_set = subset(valid.df, select = -c(gender,Partner,Dependents,StreamingMovies))
library(rpart)
library(rpart.plot)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
print(dtree_fit_gini)
pred_tree <- predict(dtree_fit_gini, test_set)
print("Confusion Matrix for Decision Tree"); table(Predicted = pred_tree, Actual = test_set$Churn)
caret::confusionMatrix(pred_Tree, test_set$Churn)
caret::confusionMatrix(pred_tree, test_set$Churn)
caret::confusionMatrix(as.factor(pred_tree), as.factor(test_set$Churn))
plot(pred_Tree)
plot(pred_tree)
set.seed(111)
# boosting
boost <- boosting(Churn ~ ., data = train_set)
# boosting
boost <- boosting(Churn ~ , data = train_set)
# boosting
boost <- boosting(Churn ~., data = train_set)
# boosting
boost <- boosting(Churn ~ ., data = dataset)
# boosting
boost <- boosting(Churn~ ., data = dataset)
# boosting
boost <- boosting(Churn ~ ., data = dataset)
library(adabag)
# boosting
boost <- boosting(Churn ~ ., data = dataset)
dataset = read.csv("customer_churn.csv")
dataset[dataset == "Yes"] <- 1
dataset[dataset == "No"] <- 0
dataset$Churn <- as.numeric(as.character(dataset$Churn))
head(dataset)
dataset = subset(dataset, select =  - customerID  )
dataset  = na.omit(dataset)
head(dataset)
train.index <- sample(c(1:dim(dataset)[1]), dim(dataset)[1]*0.67)
train.df <- dataset[train.index, ]
valid.df <-dataset[-train.index, ]
label <- length(dataset$Churn)
train_length <- length(train.df$Churn)
test_length <- length(valid.df$Churn)
H <- c(label, train_length, test_length)
M <- c("Dataset","Train","Test")
barplot(H, names.arg = M)
dim(train.df)
sapply(train.df, class)
table(train.df$Churn)
library(ROSE)
train_set <- ovun.sample(Churn~., data=train.df,
N=nrow(train.df), p=0.2,
seed=1, method="both")$data
table(data.balanced.ou$Churn)
library("party")
prop.table(table(train_set$Churn))
####################
#Feature Importance
###################
set.seed(300)
model <- rpart(Churn~., data =  train_set, method = "class")
importance <- varImp(model, scale = FALSE)
print(importance)
train_set = subset(train_set, select = -c(gender,Partner,Dependents,StreamingMovies))
test_set = subset(valid.df, select = -c(gender,Partner,Dependents,StreamingMovies))
library(rpart)
library(rpart.plot)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
print(dtree_fit_gini)
pred_tree <- predict(dtree_fit_gini, test_set)
print("Confusion Matrix for Decision Tree"); table(Predicted = pred_tree, Actual = test_set$Churn)
caret::confusionMatrix(as.factor(pred_tree), as.factor(test_set$Churn))
plot(pred_tree)
# boosting
boost <- boosting(Churn ~ ., data = train_set)
# boosting
boost <- boosting(as.factor(Churn) ~ ., data = train_set)
# boosting
train_set$Churn <- as.factor(train_set$Churn)
boost <- boosting(Churn ~ ., data = train_set)
pred <- predict(boost, test_set, type = "class")
confusionMatrix(pred, test_set$Churn)
print(pred)
confusionMatrix(as.factor(pred$class), as.factor(test_set$Churn))
boost_2 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund", mfinal = 80)
pred_2 <- predict(boost, test_set, type = "class")
confusionMatrix(as.factor(pred_2$class), as.factor(test_set$Churn))
boost_3 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund", boos = FALSE)
pred_2 <- predict(boost_2, test_set, type = "class")
confusionMatrix(as.factor(pred_2$class), as.factor(test_set$Churn))
pred_3 <- predict(boost_3, test_set, type = "class")
confusionMatrix(as.factor(pred_3$class), as.factor(test_set$Churn))
pred_Tree_pro <- predict(dtree_fit_gini, test_set , type = "prob")
pred_boost_pro <- predict(boost, test_set , type = "prob")
Label = as.numeric(test_set$Churn)
Decsion.tree.roc <- roc(Label , pred_Tree_pro[,2] )
Radnom.boost.roc <- roc(Label ,pred_boost_pro[,2] )
dataset = read.csv("customer_churn.csv")
dataset[dataset == "Yes"] <- 1
dataset[dataset == "No"] <- 0
dataset$Churn <- as.numeric(as.character(dataset$Churn))
head(dataset)
dataset = subset(dataset, select =  - customerID  )
dataset  = na.omit(dataset)
head(dataset)
train.index <- sample(c(1:dim(dataset)[1]), dim(dataset)[1]*0.67)
train.df <- dataset[train.index, ]
valid.df <-dataset[-train.index, ]
label <- length(dataset$Churn)
train_length <- length(train.df$Churn)
test_length <- length(valid.df$Churn)
H <- c(label, train_length, test_length)
M <- c("Dataset","Train","Test")
barplot(H, names.arg = M)
dim(train.df)
sapply(train.df, class)
table(train.df$Churn)
library(ROSE)
train_set <- ovun.sample(Churn~., data=train.df,
N=nrow(train.df), p=0.2,
seed=1, method="both")$data
table(data.balanced.ou$Churn)
library("party")
prop.table(table(train_set$Churn))
####################
#Feature Importance
###################
set.seed(300)
model <- rpart(Churn~., data =  train_set, method = "class")
importance <- varImp(model, scale = FALSE)
print(importance)
train_set = subset(train_set, select = -c(gender,Partner,Dependents,StreamingMovies))
test_set = subset(valid.df, select = -c(gender,Partner,Dependents,StreamingMovies))
library(rpart)
library(rpart.plot)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
print(dtree_fit_gini)
pred_tree <- predict(dtree_fit_gini, test_set)
print("Confusion Matrix for Decision Tree"); table(Predicted = pred_tree, Actual = test_set$Churn)
caret::confusionMatrix(as.factor(pred_tree), as.factor(test_set$Churn))
plot(pred_tree)
# boosting
train_set$Churn <- as.factor(train_set$Churn)
boost <- boosting(Churn ~ ., data = train_set)
pred_boost <- predict(boost, test_set, type = "class")
confusionMatrix(as.factor(pred$class), as.factor(test_set$Churn))
boost_2 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund", mfinal = 80)
Decsion.tree.roc <- roc(Label , pred_Tree_pro[,2] )
pred_Tree_pro <- predict(dtree_fit_gini, test_set , type = "prob")
Label = as.numeric(test_set$Churn)
Decsion.tree.roc <- roc(Label , pred_Tree_pro[,2] )
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
pred_2 <- predict(boost_2, test_set, type = "class")
confusionMatrix(as.factor(pred_2$class), as.factor(test_set$Churn))
boost_3 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund", boos = FALSE)
pred_3 <- predict(boost_3, test_set, type = "class")
confusionMatrix(as.factor(pred_3$class), as.factor(test_set$Churn))
pred_boost_pro <- predict(boost_2, test_set , type = "prob")
Radnom.boost.roc <- roc(Label ,pred_boost_pro[,2] )
Radnom.boost.roc <- roc(Label ,pred_boost_pro$class )
print(pred_boost_pro)
print(pred_Tree_pro)
print(pred_boost_pro[,2)
print(pred_boost_pro[,2])
print(pred_boost_pro[0,2])
Radnom.boost.roc <- roc(Label ,pred_boost_pro)
print( pred_Tree_pro[,2])
Decsion.tree.roc <- roc(Label , pred_Tree_pro[,2] )
Radnom.boost.roc <- roc(Label ,pred_boost_pro$prob)
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
plot(Radnom.boost.roc, col="blue" ,add = TRUE)
Radnom.boost.roc <- roc(Label ,pred_boost_pro[,2])
print( pred_boost_pro)
Radnom.boost.roc <- roc(Label ,pred_boost_pro$prob)
Radnom.boost.roc <- roc(Label ,pred_boost_pro$prob[,2])
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
plot(Radnom.boost.roc, col="blue" ,add = TRUE)
auc(Decsion.tree.roc)
auc(Radnom.for.roc)
auc(Radnom.boost.roc)
library(tidyverse)  # data manipulation
library(cluster)  # clustering algorithms
install.packages("factoextra")
library(factoextra)
library("Hmisc")
df <- read.csv("framingham.csv")
keeps <- c("age","male")
df_cleaned <- df[keeps]
head(df_cleaned)
names(df_cleaned)[names(df_cleaned) == "male"] <- "sex"
max = apply(df_cleaned["age"] , 2 , max)
min = apply(df_cleaned["age"], 2 , min)
scaled = as.data.frame(scale(df_cleaned["age"], center = min, scale = max - min))
head(scaled)
df_cleaned["age"] <- scale(df_cleaned["age"], center = min, scale = max - min)
head(df_cleaned)
df_cleaned <- na.omit(df_cleaned)
head(df_cleaned)
sapply(df_cleaned, class)
df_cleaned$age <- as.numeric(df_cleaned$age)
df_cleaned$sex <- as.numeric(df_cleaned$sex)
head(df_cleaned)
describe(df_cleaned)
head(df_cleaned)
set.seed(917)
library("animation")
set.seed(2345)
kmeans.ani(df_cleaned, 4)
fviz_nbclust(df_cleaned, kmeans, method = "wss")
df <- read.csv("framingham.csv")
keeps <- c("age","male")
df_cleaned <- df[keeps]
head(df_cleaned)
names(df_cleaned)[names(df_cleaned) == "male"] <- "sex"
max = apply(df_cleaned["age"] , 2 , max)
min = apply(df_cleaned["age"], 2 , min)
scaled = as.data.frame(scale(df_cleaned["age"], center = min, scale = max - min))
head(scaled)
df_cleaned["age"] <- scale(df_cleaned["age"], center = min, scale = max - min)
head(df_cleaned)
df_cleaned <- na.omit(df_cleaned)
head(df_cleaned)
sapply(df_cleaned, class)
df_cleaned$age <- as.numeric(df_cleaned$age)
df_cleaned$sex <- as.numeric(df_cleaned$sex)
head(df_cleaned)
describe(df_cleaned)
head(df_cleaned)
set.seed(917)
library("animation")
set.seed(2345)
kmeans.ani(df_cleaned, 4)
fviz_nbclust(df_cleaned, kmeans, method = "wss")
fviz_nbclust(df_cleaned, kmeans, method = "wss")
set.seed(2345)
kmeans.ani(df_cleaned, 5)
fviz_nbclust(df_cleaned, kmeans, method = "silhouette")
dataset = read.csv("customer_churn.csv")
dataset[dataset == "Yes"] <- 1
dataset[dataset == "No"] <- 0
dataset$Churn <- as.numeric(as.character(dataset$Churn))
head(dataset)
dataset = subset(dataset, select =  - customerID  )
dataset  = na.omit(dataset)
head(dataset)
train.index <- sample(c(1:dim(dataset)[1]), dim(dataset)[1]*0.67)
train.df <- dataset[train.index, ]
valid.df <-dataset[-train.index, ]
label <- length(dataset$Churn)
train_length <- length(train.df$Churn)
test_length <- length(valid.df$Churn)
H <- c(label, train_length, test_length)
M <- c("Dataset","Train","Test")
barplot(H, names.arg = M)
train_set_length <- length(train_set$Churn)
H_1 <- c(label, train_set, test_length)
M_1 <- c("Dataset","Train","Test")
barplot(H, names.arg = M)
barplot(H_1, names.arg = M_1)
nrow(train.df$Churn)
table(train.df$Churn)
prop.table(table(train.df$Churn))
dim(train.df$Churn)
dim(train.df)
prop.table(table(train_set$Churn))
train_set <- ovun.sample(Churn~., data=train.df,
N=nrow(train.df), p=0.2,
seed=1, method="both")$data
table(data.balanced.ou$Churn)
prop.table(table(train_set$Churn))
#Feature Importance
###################
set.seed(300)
model <- rpart(Churn~., data =  train_set, method = "class")
importance <- varImp(model, scale = FALSE)
print(importance)
train_set = subset(train_set, select = -c(gender,Partner,Dependents,StreamingMovies))
test_set = subset(valid.df, select = -c(gender,Partner,Dependents,StreamingMovies))
library(rpart)
library(rpart.plot)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
print(dtree_fit_gini)
print("Confusion Matrix for Decision Tree"); table(Predicted = pred_tree, Actual = test_set$Churn)
caret::confusionMatrix(as.factor(pred_tree), as.factor(test_set$Churn))
plot(pred_tree)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
pred_tree <- predict(dtree_fit_gini, test_set)
caret::confusionMatrix(as.factor(pred_tree), as.factor(test_set$Churn))
plot(pred_tree)
# boosting
set.seed(300)
train_set$Churn <- as.factor(train_set$Churn)
boost <- boosting(Churn ~ ., data = train_set)
pred_boost <- predict(boost, test_set, type = "class")
boost_2 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund", mfinal = 80)
boost_3 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund", boos = FALSE)
pred_2 <- predict(boost_2, test_set, type = "class")
pred_3 <- predict(boost_3, test_set, type = "class")
confusionMatrix(as.factor(pred$class), as.factor(test_set$Churn))
confusionMatrix(as.factor(pred_2$class), as.factor(test_set$Churn))
confusionMatrix(as.factor(pred_3$class), as.factor(test_set$Churn))
Decsion.tree.roc <- roc(Label , pred_Tree_pro[,2])
pred_Tree_pro <- predict(dtree_fit_gini, test_set , type = "prob")
print( pred_boost_pro)
pred_boost_pro <- predict(boost_2, test_set , type = "prob")
Label = as.numeric(test_set$Churn)
Decsion.tree.roc <- roc(Label , pred_Tree_pro[,2])
Radnom.boost.roc <- roc(Label ,pred_boost_pro$prob[,2])
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
plot(Radnom.boost.roc, col="blue" ,add = TRUE)
auc(Decsion.tree.roc)
auc(Radnom.boost.roc)
dataset = read.csv("customer_churn.csv")
dataset[dataset == "Yes"] <- 1
dataset[dataset == "No"] <- 0
dataset$Churn <- as.numeric(as.character(dataset$Churn))
head(dataset)
dataset = subset(dataset, select =  - customerID  )
dataset  = na.omit(dataset)
head(dataset)
train.index <- sample(c(1:dim(dataset)[1]), dim(dataset)[1]*0.67)
train.df <- dataset[train.index, ]
valid.df <-dataset[-train.index, ]
label <- length(dataset$Churn)
train_length <- length(train.df$Churn)
test_length <- length(valid.df$Churn)
H <- c(label, train_length, test_length)
M <- c("Dataset","Train","Test")
barplot(H, names.arg = M)
dim(train.df)
sapply(train.df, class)
table(train.df$Churn)
prop.table(table(train.df$Churn))
dim(train.df)
library(ROSE)
train_set <- ovun.sample(Churn~., data=train.df,
N=nrow(train.df), p=0.3,
seed=1, method="both")$data
table(data.balanced.ou$Churn)
prop.table(table(train_set$Churn))
pred_Tree_pro
#Feature Importance
###################
set.seed(300)
model <- rpart(Churn~., data =  train_set, method = "class")
importance <- varImp(model, scale = FALSE)
print(importance)
train_set = subset(train_set, select = -c(gender,Partner,Dependents,StreamingMovies))
test_set = subset(valid.df, select = -c(gender,Partner,Dependents,StreamingMovies))
library(rpart)
library(rpart.plot)
dtree_fit_gini <- train(as.factor(Churn)~., data = train_set, method = "rpart", parms = list(split = "gini"),  tuneLength = 10)
print(dtree_fit_gini)
pred_tree <- predict(dtree_fit_gini, test_set)
caret::confusionMatrix(as.factor(pred_tree), as.factor(test_set$Churn))
# boosting
set.seed(300)
train_set$Churn <- as.factor(train_set$Churn)
boost <- boosting(Churn ~ ., data = train_set)
pred_boost <- predict(boost, test_set, type = "class")
confusionMatrix(as.factor(pred$class), as.factor(test_set$Churn))
boost_2 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund", mfinal = 80)
boost_2 <- boosting(Churn ~ ., data = train_set,coeflearn = "Freund")
pred_2 <- predict(boost_2, test_set, type = "class")
confusionMatrix(as.factor(pred_2$class), as.factor(test_set$Churn))
boost_3 <- boosting(Churn ~ ., data = train_set,mfinal = 150)
pred_3 <- predict(boost_3, test_set, type = "class")
confusionMatrix(as.factor(pred_3$class), as.factor(test_set$Churn))
pred_boost_pro1 <- predict(boost, test_set , type = "prob")
pred_boost_pro2 <- predict(boost_2, test_set , type = "prob")
pred_boost_pro3 <- predict(boost_3, test_set , type = "prob")
Radnom.boost1.roc <- roc(Label ,pred_boost_pro1$prob[,2])
Radnom.boost2.roc <- roc(Label ,pred_boost_pro2$prob[,2])
Radnom.boost3.roc <- roc(Label ,pred_boost_pro3$prob[,2])
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
plot(Radnom.boost1.ro., col="blue" ,add = TRUE)
plot(Radnom.boost1.roC., col="blue" ,add = TRUE)
Radnom.boost1.roc <- roc(Label ,pred_boost_pro1$prob[,2])
Radnom.boost2.roc <- roc(Label ,pred_boost_pro2$prob[,2])
Radnom.boost3.roc <- roc(Label ,pred_boost_pro3$prob[,2])
plot(Radnom.boost1.roc, col="blue" ,add = TRUE)
plot(Radnom.boost2.roc, col="green" ,add = TRUE)
plot(Radnom.boost3.roc, col="yellow" ,add = TRUE)
pred_Tree_pro <- predict(dtree_fit_gini, test_set , type = "prob")
print( pred_boost_pro)
pred_boost_pro <- predict(boost_2, test_set , type = "prob")
pred_Tree_pro
Label = as.numeric(test_set$Churn)
Decsion.tree.roc <- roc(Label , pred_Tree_pro[,2])
Radnom.boost.roc <- roc(Label ,pred_boost_pro$prob[,2])
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
plot(Radnom.boost.roc, col="blue" ,add = TRUE)
pred_boost_pro <- predict(boost, test_set , type = "prob")
pred_boost1_pro <- predict(boost, test_set , type = "prob")
pred_boost3_pro <- predict(boost_3, test_set , type = "prob")
Radnom.boost1.roc <- roc(Label ,pred_boost1_pro$prob[,2])
Radnom.boost2.roc <- roc(Label ,pred_boost2_pro$prob[,2])
Radnom.boost3.roc <- roc(Label ,pred_boost3_pro$prob[,2])
pred_boost2_pro <- predict(boost_2, test_set , type = "prob")
Radnom.boost2.roc <- roc(Label ,pred_boost2_pro$prob[,2])
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
plot(Decsion.tree.roc, col="red" , legecy.axis = TRUE)
plot(Radnom.boost1.roc, col="blue" ,add = TRUE)
plot(Radnom.boost2.roc, col="green" ,add = TRUE)
plot(Radnom.boost3.roc, col="yellow" ,add = TRUE)
auc(Decsion.tree.roc)
auc(Radnom.boost.roc)
auc(Radnom.boost1.roc)
auc(Radnom.boost2.roc)
auc(Radnom.boost3.roc)
